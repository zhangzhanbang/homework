---
  title : ELSI of automated vehicles
---

### 飞速发展的自动驾驶

------

> 2014年12月，严格意义上的自动驾驶汽车由Google研发成功，实现全自动驾驶。
>
> 2016年之后，各大企业先后开始加入自动驾驶研发竞赛。
>
> 2017年，百度发布Apollo自动驾驶开放软件合作平台。
>
> 2018年，美国通用汽车计划量产一款没有方向盘和制动踏板的无人驾驶汽车，于2019年推出。
>
> 这些历史性的转折都在诠释着一件事：无人驾驶正在从实验室走向商业产品化的现实，无人驾驶的未来不再遥远。

![p1](https://github.com/zhangzhanbang/homework/raw/gh-pages/images/p2.jpg)

​																	*谷歌无人驾驶汽车*

### 无法避免的伦理规范问题

------

> ​	自动驾驶汽车的到来确实令人兴奋，它会让通勤变得更轻松，把堵车浪费的时间还给每个人。此外，它还能解决老年人和残疾人的出行问题，并挽救每年因交通事故枉死的数万条生命。
>
> ​	即便如此，进入自动驾驶时代后，车祸仍不可避免。一旦发生事故，自动驾驶汽车面临两难困境时，到底该牺牲谁？谁又有权决定他人的生死？​	

**电车难题**

![img](https://image.jiqizhixin.com/uploads/editor/50c9bcae-cc23-4078-ba95-cdc5f74a49b2/1541501262349.png)

> ​	当前有关自动驾驶汽车伦理困境的讨论主要与道德哲学中著名的“电车难题”相关。
>
> ​	“电车难题”是由哲学家Philippa Foot提出的著名思想实验：你可以通过变轨使一辆失控的电车撞向1个人或者不变轨撞向5个人，但无论你做什么选择，都会有人被疾驰的电车夺取生命。
>
> ​	同样的，想象一下，你的自动驾驶汽车停在路口，等着面前的行人过马路，这时，突然有一辆失控的卡车在你的车后冲了过来，追尾事故看起来无法避免。这时，你的AI系统会如何选择呢？马上躲开，规避对自己的伤害，那么这辆卡车就会冲进路口，碾压行人；若不躲开，就会牺牲车上乘客（也就是你自己）的生命。
>
> ​	到底应该牺牲车上乘客还是路上行人？这个问题恐怕难以回答。
>
> ​	类似的“电车问题”在自动驾驶问题中可衍生出多个变种。比如说面对在高速公路上出现的野生动物，面对有不同防护措施的行人或摩托车、甚至面对众多放学后穿过马路的小孩，又该如何抉择？此外，公共自动驾驶车辆遭遇交通事故又会陷入怎样的伦理困境？这值得我们深思。

**道德算法该如何设计？**

![重读电车难题：当无人车不得不杀人 谁决定谁生死](http://cms-bucket.nosdn.127.net/9740015d0bdc4ccd8a1f5da8f0fc0f5b20170924111144.jpeg?imageView&thumbnail=550x0)

> ​	由电车问题所引申出，自动驾驶汽车的“道德算法”，应当以减少死亡为原则还是以保护车主为原则？
>
> ​	面对这一算法难题，法国科学家采用“实验伦理学”的方法，在“Mechanical Turk”网络平台进行了6项网上调查，调查结果显示：
>
> ​	第一，自动驾驶汽车算法“道德算法”的决定应由三个主体参与，即政府提出汽车制造商可选择的编程类型，制造商进行具体编码，车主作为消费者可选择购买不同算法和厂商的车型。这意味着“道德算法”透明化，公众希望市场提供多样“道德算法”车型，拥有自己的选择权。
>
> ​	第二，在面对撞向更多路人还是牺牲自己的选择时，大部分人倾向于功利主义的道德算法，即去拯救更多的生命。但在选择购买何种算法的自动驾驶汽车时，人们又绝对倾向于购买基于自我保护算法的自动驾驶汽车，而非功利算法的汽车。
>
> ​	在功利主义原则与自我保护原则发生矛盾时，该如何抉择？2017年6月，德国在全球范围内首次系统提出了自动驾驶的20条伦理，这些伦理规则的核心内容其中包括：保护个人优先于其他一切功利主义的考虑。
>
> ​	此外，不同地域文化差异对同样的道德难题也会有不同的答案，在设计道德算法的时候，是否也需要考虑道德文化多元主义的影响，根据各个地区国家的文化情况设计不同的道德算法呢？		

**工程师的思考？**

![有个无人驾驶汽车的伦理问题，你一定没想过](https://static.leiphone.com/uploads/new/article/740_740/201507/55ac91e13dc17.jpg?imageMogr2/format/jpg/quality/90)

> ​	Karl Iagnemma（Aptiv Automated Mobility 总裁兼自动驾驶车辆公司nuTonomy的共同创办人）表示：“从工程师的角度看，解决电车难题需要基于两点考虑。首先，谁都无法确定正确的解决方法是什么，甚至都无法确定是否存在解决方法。其次，像这样的事故概率是极其微小的，并且自动驾驶技术会让这一概率继续减小。”
>
> ​	道德困境暂且无法解决，工程师更关注基础性的问题：比如训练机器辨识骑自行车的人和停靠的车辆或是行驶的车辆。同时，工程师也正在让技术进行基本的利弊权衡判断。
>
> ​	来自开发自动驾驶汽车感知系统的DeepScale公司的首席执行官Forrest Iandola介绍：“自动驾驶汽车会将检测到的目标分为从脆弱到不脆弱的几个等级。其中，最重要的脆弱对象是毫无防卫的人类，而停靠的汽车或是交通路标则被分类为不脆弱——也就是汽车在不得已的情况下会选择撞上的对象。”

### 多主体的责任分配

------

> ​	如果自动驾驶汽车在公共道路上致人伤亡、致财产毁损，法律责任应如何分担？
>
> ​	从2014年开发出第一辆真正意义上的自动驾驶汽车至今，已经发生了至少12起自动驾驶汽车的车祸，2018年，Uber自动驾驶汽车在美国发生全球首次致路人死亡事件。即便多数事故原因与自动驾驶无关，又或者在如今的法律框架下自动驾驶被判定为无责，在自动驾驶汽车完全实现大规模商用后，一旦发生交通事故，势必挑战现行的法律法规，其中包含了设计、制造、用户的多重法律关系。
>
> ​	自动驾驶汽车事故风险的责任该如何分配？政府监管部门、制造商、车主、驾驶人及行人等主体究竟应分别承担怎样的责任？以上问题仍有待进一步讨论。

